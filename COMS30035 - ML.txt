#separator:tab
#html:true
<div>What is supervised learning?</div><div></div>	A type of machine learning where the model learns from data that is labelled. Each input is paired with a correct output or 'target'.
<div>What is unsupervised learning?</div><div></div>	A type of machine learning where the model learns from unlabelled data, trying to find patterns or structure on its own.
<div>What is reinforcement learning?</div><div></div>	A type of machine learning where a model (or 'agent') learns by performing actions in an environment and receiving rewards or punishments.
<div>Define overfitting</div><div></div>	When a model is too complex and learns the training data too well, including its noise and random fluctuations. This makes it perform poorly on new, unseen data.
<div><div><div>Define underfitting</div><div></div></div><div></div></div><div></div>	When a model is too simple to capture the underlying patterns in the data, leading to poor performance on both training and new data.
<div>What is the purpose of model selection?</div><div></div>	To choose the best model for a given task by finding a balance that avoids both overfitting and underfitting, allowing the model to generalise well to new data.
<div>What are the roles of the training, validation, and testing datasets?</div><div></div>	<div>Training set: Used to train and optimise the model's parameters. <sup></sup><sup></sup><sup></sup><sup></sup><div></div><div></div></div><div></div><div>Validation set: Used to tune the model and select the best one during training. <sup></sup><sup></sup><sup></sup><sup></sup><div></div><div></div></div><div></div><div>Testing set: Used only after training is complete to provide an unbiased evaluation of the final model's performance on unseen data.&nbsp;</div>
<div>What is the curse of dimensionality?</div><div></div>	The problem where, as the number of features (dimensions) in the data increases, the amount of data needed to effectively cover the space grows exponentially.
"<div>What is the ""no free lunch"" theorem in machine learning?</div><div></div>"	The principle that there is no single machine learning model that is universally the best for every problem. The choice of model depends on the specific task and data.
<div>What is the difference between parametric and non-parametric models?</div><div></div>	Parametric models have a fixed number of parameters, regardless of the amount of training data.&nbsp;Non-parametric models have a number of parameters that can grow as the amount of training data increases.&nbsp;Parametric models are often simpler, faster to fit, and may require less data. Non-parametric models make less assumptions, usually produce better models, but are more expensive to train.
<div>What is the goal of a regression task?</div><div></div>	To find the relationship between variables in order to predict a continuous numerical output.
What is the formula for the least squares solution for linear regression parameters, \(\hat{\theta}\)?	\(\hat{\theta}=(X^{T}X)^{-1}X^{T}y\)&nbsp;This formula finds the parameters that minimise the sum of the squared differences between the predicted and actual values.
What is Maximum Likelihood Estimation (MLE)?	A method for estimating the parameters of a probabilistic model by finding the parameter values that maximise the likelihood of the observed data having occurred.
What does it mean for a dataset to be linearly separable?	The data points from different classes can be completely separated by a single straight line (or a plane/hyperplane in higher dimensions).
What type of function does logistic regression use to model the probability of a class?	The logistic sigmoid function, which produces an 'S'-shaped curve that maps any real-valued number to a value between 0 and 1.
What is gradient descent?	An optimisation algorithm used to find the minimum of a function. It works by iteratively taking steps in the opposite direction of the function's gradient (the direction of steepest descent).
What is cross-validation?	The original data is split into&nbsp;\(S\)&nbsp;folds. The procedure cycles through these folds, using&nbsp;\((S-1)/S\)&nbsp;of the data for training and the remaining&nbsp;\(1/S\)&nbsp;for validation in each run. The performance is typically computed as the average error across all&nbsp;\(S\)&nbsp;folds. This method is a solution to the problem that simply splitting the data leaves less data available for training, and it helps avoid tuning on a single, potentially small, validation set.
How can linear regression be extended to handle complexity beyond simple linear relationships with the original data&nbsp;\(x\)?	Linear regression can be applied to a feature vector&nbsp;\(\phi(x)\)&nbsp;rather than the original data&nbsp;\(x\), using the model:&nbsp;\[p(y|\phi(x), w) = w^\top \phi(x) + \epsilon\]<br>
What is the relationship between the least-squares solution and the Maximum Likelihood Estimation (MLE) solution in linear regression?	The least-squares solution is also the maximum likelihood solution. This is due to the assumption that the error&nbsp;\(\epsilon\)&nbsp;is Gaussian distributed.
For an input&nbsp;\(x\)&nbsp;and two classes,&nbsp;\(C_1\)&nbsp;and&nbsp;\(C_2\), how does Linear Discriminant assign a class label?	Linear Discriminant computes&nbsp;\(y = w^\top x\). It assigns&nbsp;\(x\)&nbsp;to class&nbsp;\(C_1\)&nbsp;if&nbsp;\(y \ge 0\), and assigns&nbsp;\(x\)&nbsp;to class&nbsp;\(C_2\)&nbsp;otherwise.
What two key assumptions are made about the data distribution to enable the parameters of a Linear Discriminant model to be learnt?	1) Data for each class must have a Gaussian distribution. <br>2) These two Gaussian distributions must share the same covariance matrix.
How are the parameters for Linear Discriminant found under the necessary distributional assumptions?	The parameters are found by applying Maximum Likelihood Estimation (MLE).
What is the definition of the logistic sigmoid function,&nbsp;\(\sigma(a)\).	\[\sigma(a) = \frac{1}{1 + \exp(-a)}\]<br>
What is the logistic regression model used for two-class classification?	The logistic regression model uses the sigmoid function to define the posterior probabilities for class&nbsp;\(C_1\)&nbsp;and&nbsp;\(C_2\): \(p(C_1|x) = \sigma(w^\top x)\),&nbsp;\(p(C_2|x) = 1 - p(C_1|x)\).
How are the Maximum Likelihood Estimation (MLE) parameters for logistic regression found?	By using gradient descent or by using the closed-form formula for the MLE parameters.
What are neural network weights?	These are the parameters of a neural network. A unit&nbsp;\(j\)&nbsp;computes a value&nbsp;\(a_j\)&nbsp;which is defined as a weighted sum of its inputs from the previous layer, utilising these weights (\(w_{ji}\)). The learning process involves iteratively updating these weights (parameters) by descending the gradient to minimise the error.
What is a neural network activation function?	A function applied by a unit&nbsp;\(j\)&nbsp;in a neural network (excluding the input layer). After computing the weighted sum of inputs (\(a_j\)), this sum is passed to a nonlinear activation function&nbsp;\(h\)&nbsp;to produce the unit's output value (\(z_j\)). These functions must be non-linear; otherwise, the entire neural network would simply represent a linear function, negating the benefit of using multiple layers (as you could just use linear or logistic regression).
What is the input layer of a neural network?	This is the initial layer of a neural network where the data is fed into the model.
What is a hidden layer in a neural network?	Any layer between the input and output layers.
What is the output layer of a neural network?	The final layer of a neural network that generates the model's prediction or outcome. For classification problems, an activation function like a sigmoid is typically used at the output layer.
What is a cost/loss function?	A function used to quantify the difference between the network's output and the target value (error). The goal of optimising the network is to minimize this function. In methods like weight decay, a regularisation term is added to this function to penalise large weights.
What is a forward pass?	The computational stage where an input vector is applied to the network, and activations are propagated through all units, layer by layer, from the input layer up to the output layer, resulting in the prediction. We need forward propagation to compute quantities used in backpropagation.
What is a backwards pass?	The stage following the forward pass where the error signal is propagated backwards across the network using the back propagation algorithm to compute the error gradient with respect to the weights. The computed gradient is then used to update the network parameters.
What is the vanishing gradient problem?	A phenomenon encountered when training deep neural networks where the gradient, during the backward pass, becomes very small. This prevents effective weight updates via gradient descent.
What is the exploding gradient problem?	A phenomenon encountered when training deep neural networks where the gradient becomes very large.
What is gradient clipping?	A method used to mitigate the exploding gradient problem by capping the magnitude of the gradient. The clipped gradient \(g'\)&nbsp;is calculated using the formula&nbsp;\(g' = \min \left( 1, \frac{c}{||g||} \right) g\), ensuring that&nbsp;\(g'\)&nbsp;points in the same direction as the original gradient&nbsp;\(g\)&nbsp;but with a restricted magnitude.
What are non-saturating activation functions?	Activation functions that do not converge on a constant value for extremely negative or positive input values.&nbsp;Standard sigmoid functions saturate at large inputs, causing their gradients to become zero, which contributes to the vanishing gradient problem. Choosing non-saturating functions, such as ReLU variants, addresses this issue.
What is a residual network?	A residual network is composed of residual layers. Each layer is defined by the function&nbsp;\(F'_l(x) = F_l(x) + x\), where&nbsp;\(F_l(x)\)&nbsp;represents the standard linear-activation-linear mapping. The primary benefit of this design is that it offers a 'short cut' which allows gradients to flow directly from the output layer to any previous layer, aiding in the training of very deep networks.
Why is parameter initialisation important?	The optimisation landscape for neural network training is non-convex (possessing many local minima/'valleys'), the starting position (the choice of initial weights) is important as standard gradient descent will converge to the local optimum corresponding to that starting point.
What is early stopping?	A method used to prevent overfitting in neural networks (and other models). A validation dataset is created, and training is stopped when the error on this validation set begins to increase, indicating that the model is starting to overfit the training data.
What is weight decay?	Also known as&nbsp;\(\ell_2\)&nbsp;regularisation, this method reduces overfitting by modifying the loss function. A penalty term,&nbsp;\(\lambda w^\top w\)&nbsp;(where&nbsp;\(w\)&nbsp;is the weight vector and&nbsp;\(\lambda &gt; 0\)&nbsp;is a user-chosen parameter), is added to the cost function to penalize large weights. This penalty term is the square of the 2-norm, or Euclidean norm, of the weight vector, \(||w||_2^2\).
What is dropout?	"A regularisation method for preventing overfitting in neural networks. During training, a unit's outgoing connections are randomly deactivated (removed) with a specified probability. This is done on a per-example basis—a new ""thinned network"" is sampled and trained for each presentation of a training case. This process forces units to become robust and prevents them from learning complex, fragile dependencies on specific other units."
How does an individual unit compute its output value?	A unit&nbsp;\(j\)&nbsp;first computes&nbsp;\(a_j\), a weighted sum of its inputs (\(z_i\)) from the previous layer, and then passes&nbsp;\(a_j\)&nbsp;to a nonlinear activation function&nbsp;\(h\)&nbsp;to determine its output&nbsp;\(z_j\):&nbsp;\(a_j = \sum_i w_{ji}z_i\), \(z_j = h(a_j)\).
What is the back propagation formula?	"\[\delta_j = h'(a_j) \sum_k w_{kj}\delta_k\]\(\mathbf{\delta_j}\): The error signal for unit&nbsp;\(j\).<br>\(a_j\)<span style=""white-space: pre;"">:</span>&nbsp;The total weighted sum of inputs received by unit&nbsp;\(j\)&nbsp;before the activation function is applied.<br>\(h'(a_j)\): Represents the derivative of the activation function,&nbsp;\(h\).<br>\(\sum_k\): Indicates the summation over all units&nbsp;\(k\)&nbsp;in the subsequent layer to which unit&nbsp;\(j\)&nbsp;sends connections.<br>\(w_{kj}\): The weight parameter connecting unit&nbsp;\(j\)&nbsp;to unit&nbsp;\(k\)&nbsp;in the next layer.<br>\(\delta_k\): The previously calculated error signal (\(\equiv \frac{\partial E_n}{\partial a_k}\)) for unit&nbsp;\(k\)&nbsp;in the layer subsequent to&nbsp;\(j\)."
What is the ReLU formula?	\[f(x) = max(0,x)\]<br>
What is a Classification Tree?	A classification tree is a type of decision tree used in supervised learning where the goal is to assign an input to one of several category labels (classes). When traversing the binary decision tree, the final decision is made by a leaf node. For classification tasks, this leaf node is responsible for assigning a decision, which may be a class label or a probability distribution over class labels.
What is a Regression Tree?	A regression tree is a type of decision tree used in supervised learning where the goal is to predict a numerical output (a scalar value). The final prediction is assigned by a leaf node, which is responsible for giving a scalar value for regression tasks.
Are decision trees parametric or non-parametric?	Trees are a nonparametric method. (more data = more parameters)
Describe the standard greedy algorithm (CART) for learning trees, including the final pruning stage.	1. Start from the root node.<br>2. Run an exhaustive search over every possible input variable and threshold for a new split.<br>3. For each possible split, compute the average of the target variable for the proposed leaves and then calculate the error (or cost) that would result if the tree construction stopped there.<br>4. Choose the variable and threshold that minimise the error.<br>5. Repeat this process until a stopping condition is met, typically until there are only n data points associated with each leaf node. The error minimized depends on the task: sum-of-squares for regression, and cross-entropy or Gini impurity for classification. <br>The Final Pruning Stage: After the full tree is grown, the final step involves pruning back the tree. Pruning balances the residual training-set error against the model complexity. Pruning removes branches that do not reduce the error by more than a small tolerance value (ϵ). This is often achieved bottom-up by combining branches (merging leaves).
What is the main flaw of decision trees?	If the optimal decision boundary for the classification or regression task is not aligned with the axes of the input variables, the tree learning process may require a lot of splits to approximate the boundary effectively.
What is a kernel function?	A function&nbsp;\(k(x,x')\)&nbsp;that intrinsically measures the degree of similarity between two raw data vectors,&nbsp;\(x\)&nbsp;and&nbsp;\(x'\).
What is the kernel trick?	A computational shortcut that involves evaluating the kernel function directly without first needing to explicitly compute the feature vectors&nbsp;\(ϕ(x)\)&nbsp;and&nbsp;\(ϕ(x')\)&nbsp;and then calculating their scalar product.
What properties must a custom kernel function have?	It must be symmetric.&nbsp;It is formally equivalent to the scalar product of the corresponding feature vectors in a transformed feature space:&nbsp;\(k(x,x′)=ϕ(x)^T ϕ(x′)\). The resulting Gram matrix must be symmetric and positive semidefinite.
What is the Gram Matrix?	A matrix defined as&nbsp;\(K=ΦΦ^T\), where&nbsp;\(Φ\)&nbsp;is the design matrix. The entry \(K_{nm}\)​ represents the kernel similarity&nbsp;\(k(x_n,x_m)\)&nbsp;between the n-th and m-th data point in the training set.&nbsp;The Gram matrix contains all the pairwise similarities computed by the kernel function across the entire training dataset.
What is the margin in linear classification?	The distance from the separating hyperplane to the closest training datapoint.
Why are SVMs a type of&nbsp;maximum margin classifiers?	They choose the hyperplane that actively maximises this distance to provide a robust separation between classes.
What are support vectors?	These are considered the training data points 'that matter' for defining the decision boundary. Mathematically, they are defined as those data points&nbsp;whose corresponding dual parameter is non-zero. Only these vectors are needed to make predictions for new data points. They are the data points that lie closest to the separating hyperplane.
What is the soft margin approach?	It relaxes the strict linear separability constraint to allow for a wider margin, even if it means some training points fall inside the margin or are misclassified. It is often used to prevent overfitting.
What are slack variables?	Variables introduced in the soft margin optimisation problem to quantify the degree of violation of the margin constraint by each training data point.
What forms of learning require teaching signals? (Ie, to be told what is correct)	Supervised Learning (Targets/Labelled data) and Reinforcement Learning (Rewards)
<div><div>If logistic regression gives very similar results to the linear discriminant, why might we want to use it?</div></div>	Because it also gives us p(C|x),&nbsp;which can be&nbsp;very useful in practice. We know how uncertain the model is about its decision. (Think about the cat classifier. Linear discriminant would say it is or is not a cat. While regression says it is a cat with 0.86 certainty or something).
<div><div>What is the advantage of choosing differentiable activation functions?</div></div>	"Having differentiable activation functions allows us to compute the 
gradient of the error with respect to network weights thus allowing us 
to use gradient descent to fit weights to the data."
What is the&nbsp;role of the regularisation parameter in soft margins?	The regularisation parameter,&nbsp;\(C\), appears in the soft margin primal optimisation objective:&nbsp;\(\min \frac{1}{2} \mathbf{w}^{\top}\mathbf{w} + C \sum_{n=1}^{N} \xi_n\).&nbsp;The value of \(C\)&nbsp;dictates the trade-off between two competing goals: maximising the margin and **minimising the training error. A large value of $C$ means that misclassification is heavily penalised.
How can SVMs be extended to deal with having more than two classes?	<div>One-vs-One (OVO): Trains \(k(k-1)/2\)&nbsp;classifiers, one for each pair of classes. Predicts by majority vote.<br></div><div>One-vs-Rest (OVR): Trains&nbsp;\(k\)&nbsp;classifiers, one for each class against all remaining classes.</div>
What is the RBF kernel?	<div>The Radial Basis Function kernel is defined as&nbsp;\(k(\mathbf{x}, \mathbf{x}') = \exp(-\gamma\|\mathbf{x}- \mathbf{x}'\|^2)\).<br></div><div>Feature Space: Maps data to an infinite-dimensional space (making the model non-parametric).</div><div>Parameter&nbsp;\(\gamma\): Controls the influence radius of support vectors.</div><div>Low&nbsp;\(\gamma\): Far influence (smoother decision boundary).</div><div>High&nbsp;\(\gamma\): Close influence (can lead to overfitting).</div>
How do kernel-based methods make predictions?	<div>Prediction Formula: They predict a new point&nbsp;\(x\)&nbsp;by computing a weighted sum of its similarities (using the kernel&nbsp;\(k\)) to all training points&nbsp;\(x_n\)​:&nbsp;</div><div>The Problem: This seems to require storing the entire training set to make any new predictions.<br></div>\(y(\mathbf{x}) = \sum_{n=1}^{N} a_n k(\mathbf{x}_n, \mathbf{x}) + b\)<div>SVM's Solution (Sparsity): SVMs are efficient because most of the weights&nbsp;\(a_n\)&nbsp;become zero. Only the non-zero points, the Support Vectors (SVs), are needed for prediction.<br></div>
What graphical element is fundamental to defining the structure of a Bayesian network?	A Directed Acyclic Graph (DAG). This is a graph structure containing nodes (random variables) and directed edges (arrows). It must be acyclic, meaning there are no directed paths that return to the starting node.
Define conditional independence between random variables,&nbsp;\(x\)&nbsp;and&nbsp;\(y\),&nbsp;given a set,&nbsp;\(S\),&nbsp;of random variables.	\(x\)&nbsp;is independent of&nbsp;\(y\)&nbsp;conditional on&nbsp;\(S\)&nbsp;if and only if&nbsp;\(P(x, y |S) = P(x |S)P(y |S)\). This is equivalent to&nbsp;\(P(x |S) = P(x |y ,S)\). Intuitively, once the value of&nbsp;\(S\)&nbsp;is known, knowing&nbsp;\(y\)&nbsp;provides no additional information about&nbsp;\(x\).
What is a Bayesian network (BN)?	A type of Probabilistic Graphical Model (PGM). It provides a graphical representation of how a joint distribution factorises by explicitly depicting the conditional independence relations present within that distribution.
In a Bayesian network, if there is an arrow from node A to node B, what is A called relative to B?	A is a parent*of B. The set of parents of a node&nbsp;\(x_k\)&nbsp;is typically denoted \(\text{pa}_k\).
When applying d-separation, which nodes are considered descendants of a collider?	A descendant is any node reachable from the collider by following the direction of the arrows.&nbsp;Descendants of a collider are important because if they are included in the conditioning set, they can unblock the path through the collider.
What defines a path in a Bayesian network?	A path is a sequence of connected nodes in the DAG, regardless of the arrow direction along the sequence.
What is a collider on a path in a Bayesian network?	A node&nbsp;\(C\)&nbsp;is a collider on a path if the path enters&nbsp;\(C\)&nbsp;via two incoming arrows, meaning both arrows on that specific path point into it (e.g.,&nbsp;\(A \rightarrow C \leftarrow B\)). Conditioning on a collider or one of its descendants unblocks the path,.
State the two conditions under which a path is considered blocked by a set of conditioning nodes&nbsp;\(S\).	A path is blocked by&nbsp;\(S\)&nbsp;if at least one of the following is true:<br>1. There is a collider on the path that is not in&nbsp;\(S\)&nbsp;and none of its descendants are in&nbsp;\(S\). As, if the collider or a descendant is in&nbsp;\(S\), the path is unblocked.<br>2. There is a non-collider on the path that is in&nbsp;\(S\).<br>If all paths between two nodes are blocked by&nbsp;\(S\), they are d-separated.
State the general factorisation of the joint probability distribution&nbsp;\(p(\mathbf{x})\)&nbsp;defined by the structure of a given Bayesian network.	The joint distribution \(p(\mathbf{x})\)&nbsp;over&nbsp;\(K\)&nbsp;variables \(x_1, \ldots, x_K\)&nbsp;factorises as:<br>\(p(\mathbf{x}) = \prod_{k=1}^{K} p(x_k | \text{pa}_k) \text{}\)<br>This formula holds because the DAG structure implies that the conditional distribution of any variable \(x_k\)&nbsp;depends only on its immediate parents (\(\text{pa}_k\)).
How to use d-separation to check for conditional independence relations in a Bayesian network?	Two nodes are deemed conditionally independent given a set if and only if they are d-separated by that set.
What is the Likelihood?	The Likelihood, denoted \(P(D|\theta)\), is the conditional probability distribution of observing the data&nbsp;\(D\)&nbsp;given specific values for the model parameters&nbsp;\(\theta\).
What is the Posterior distribution?	The Posterior distribution, denoted \(P(\theta|D=d)\), is the distribution representing the updated beliefs about the model parameters&nbsp;\(\theta\)&nbsp;after the observed data&nbsp;\(d\)&nbsp;has been taken into account. Computing this distribution is the conceptual goal of the Bayesian approach, typically achieved using Bayes’ theorem: \(P(\theta|D=d) \propto P(\theta)P(D=d|\theta)\).
In the Bayesian approach, how are parameters, data, and unobserved (latent) variables represented?	In the Bayesian approach, the parameters, the data , and any unobserved (latent) variables are all represented as random variables within a joint probability distribution. The unknown quantities (parameters and latent variables) are specifically treated as unobserved random variables, while the known quantities (the data) are treated as observed random variables.
