#separator:tab
#html:true
<div>What is supervised learning?</div><div></div>	A type of machine learning where the model learns from data that is labelled. Each input is paired with a correct output or 'target'.
<div>What is unsupervised learning?</div><div></div>	A type of machine learning where the model learns from unlabelled data, trying to find patterns or structure on its own.
<div>What is reinforcement learning?</div><div></div>	A type of machine learning where a model (or 'agent') learns by performing actions in an environment and receiving rewards or punishments.
<div>Define overfitting</div><div></div>	When a model is too complex and learns the training data too well, including its noise and random fluctuations. This makes it perform poorly on new, unseen data.
<div><div><div>Define underfitting</div><div></div></div><div></div></div><div></div>	When a model is too simple to capture the underlying patterns in the data, leading to poor performance on both training and new data.
<div>What is the purpose of model selection?</div><div></div>	To choose the best model for a given task by finding a balance that avoids both overfitting and underfitting, allowing the model to generalise well to new data.
<div>What are the roles of the training, validation, and testing datasets?</div><div></div>	<div>Training set: Used to train and optimise the model's parameters. <sup></sup><sup></sup><sup></sup><sup></sup><div></div><div></div></div><div></div><div>Validation set: Used to tune the model and select the best one during training. <sup></sup><sup></sup><sup></sup><sup></sup><div></div><div></div></div><div></div><div>Testing set: Used only after training is complete to provide an unbiased evaluation of the final model's performance on unseen data.&nbsp;</div>
<div>What is the curse of dimensionality?</div><div></div>	The problem where, as the number of features (dimensions) in the data increases, the amount of data needed to effectively cover the space grows exponentially.
"<div>What is the ""no free lunch"" theorem in machine learning?</div><div></div>"	The principle that there is no single machine learning model that is universally the best for every problem. The choice of model depends on the specific task and data.
<div>What is the difference between parametric and non-parametric models?</div><div></div>	Parametric models have a fixed number of parameters, regardless of the amount of training data.&nbsp;Non-parametric models have a number of parameters that can grow as the amount of training data increases.&nbsp;Parametric models are often simpler, faster to fit, and may require less data. Non-parametric models make less assumptions, usually produce better models, but are more expensive to train.
<div>What is the goal of a regression task?</div><div></div>	To find the relationship between variables in order to predict a continuous numerical output.
What is the formula for the least squares solution for linear regression parameters, \(\hat{\theta}\)?	\(\hat{\theta}=(X^{T}X)^{-1}X^{T}y\)&nbsp;This formula finds the parameters that minimise the sum of the squared differences between the predicted and actual values.
What is Maximum Likelihood Estimation (MLE)?	A method for estimating the parameters of a probabilistic model by finding the parameter values that maximise the likelihood of the observed data having occurred.
What does it mean for a dataset to be linearly separable?	The data points from different classes can be completely separated by a single straight line (or a plane/hyperplane in higher dimensions).
What type of function does logistic regression use to model the probability of a class?	The logistic sigmoid function, which produces an 'S'-shaped curve that maps any real-valued number to a value between 0 and 1.
What is gradient descent?	An optimisation algorithm used to find the minimum of a function. It works by iteratively taking steps in the opposite direction of the function's gradient (the direction of steepest descent).
What is cross-validation?	The original data is split into&nbsp;\(S\)&nbsp;folds. The procedure cycles through these folds, using&nbsp;\((S-1)/S\)&nbsp;of the data for training and the remaining&nbsp;\(1/S\)&nbsp;for validation in each run. The performance is typically computed as the average error across all&nbsp;\(S\)&nbsp;folds. This method is a solution to the problem that simply splitting the data leaves less data available for training, and it helps avoid tuning on a single, potentially small, validation set.
How can linear regression be extended to handle complexity beyond simple linear relationships with the original data&nbsp;\(x\)?	Linear regression can be applied to a feature vector&nbsp;\(\phi(x)\)&nbsp;rather than the original data&nbsp;\(x\), using the model:&nbsp;\[p(y|\phi(x), w) = w^\top \phi(x) + \epsilon\]<br>
What is the relationship between the least-squares solution and the Maximum Likelihood Estimation (MLE) solution in linear regression?	The least-squares solution is also the maximum likelihood solution. This is due to the assumption that the error&nbsp;\(\epsilon\)&nbsp;is Gaussian distributed.
For an input&nbsp;\(x\)&nbsp;and two classes,&nbsp;\(C_1\)&nbsp;and&nbsp;\(C_2\), how does Linear Discriminant assign a class label?	Linear Discriminant computes&nbsp;\(y = w^\top x\). It assigns&nbsp;\(x\)&nbsp;to class&nbsp;\(C_1\)&nbsp;if&nbsp;\(y \ge 0\), and assigns&nbsp;\(x\)&nbsp;to class&nbsp;\(C_2\)&nbsp;otherwise.
What two key assumptions are made about the data distribution to enable the parameters of a Linear Discriminant model to be learnt?	1) Data for each class must have a Gaussian distribution. <br>2) These two Gaussian distributions must share the same covariance matrix.
How are the parameters for Linear Discriminant found under the necessary distributional assumptions?	The parameters are found by applying Maximum Likelihood Estimation (MLE).
What is the definition of the logistic sigmoid function,&nbsp;\(\sigma(a)\).	\[\sigma(a) = \frac{1}{1 + \exp(-a)}\]<br>
What is the logistic regression model used for two-class classification?	The logistic regression model uses the sigmoid function to define the posterior probabilities for class&nbsp;\(C_1\)&nbsp;and&nbsp;\(C_2\): \(p(C_1|x) = \sigma(w^\top x)\),&nbsp;\(p(C_2|x) = 1 - p(C_1|x)\).
How are the Maximum Likelihood Estimation (MLE) parameters for logistic regression found?	By using gradient descent.
What are neural network weights?	These are the parameters of a neural network. A unit&nbsp;\(j\)&nbsp;computes a value&nbsp;\(a_j\)&nbsp;which is defined as a weighted sum of its inputs from the previous layer, utilising these weights (\(w_{ji}\)). The learning process involves iteratively updating these weights (parameters) by descending the gradient to minimise the error.
What is a neural network activation function?	A function applied by a unit&nbsp;\(j\)&nbsp;in a neural network (excluding the input layer). After computing the weighted sum of inputs (\(a_j\)), this sum is passed to a nonlinear activation function&nbsp;\(h\)&nbsp;to produce the unit's output value (\(z_j\)). These functions must be non-linear; otherwise, the entire neural network would simply represent a linear function, negating the benefit of using multiple layers (as you could just use linear or logistic regression).
What is the input layer of a neural network?	This is the initial layer of a neural network where the data is fed into the model.
What is a hidden layer in a neural network?	Any layer between the input and output layers.
What is the output layer of a neural network?	The final layer of a neural network that generates the model's prediction or outcome. For classification problems, an activation function like a sigmoid is typically used at the output layer.
What is a cost/loss function?	A function used to quantify the difference between the network's output and the target value (error). The goal of optimising the network is to minimize this function. In methods like weight decay, a regularisation term is added to this function to penalise large weights.
What is a forward pass?	The computational stage where an input vector is applied to the network, and activations are propagated through all units, layer by layer, from the input layer up to the output layer, resulting in the prediction.
What is a backwards pass?	The stage following the forward pass where the error signal is propagated backwards across the network using the back propagation algorithm to compute the error gradient with respect to the weights. The computed gradient is then used to update the network parameters.
What is the vanishing gradient problem?	A phenomenon encountered when training deep neural networks where the gradient, during the backward pass, becomes very small. This prevents effective weight updates via gradient descent.
What is the exploding gradient problem?	A phenomenon encountered when training deep neural networks where the gradient becomes very large.
What is gradient clipping?	A method used to mitigate the exploding gradient problem by capping the magnitude of the gradient. The clipped gradient \(g'\)&nbsp;is calculated using the formula&nbsp;\(g' = \min \left( 1, \frac{c}{||g||} \right) g\), ensuring that&nbsp;\(g'\)&nbsp;points in the same direction as the original gradient&nbsp;\(g\)&nbsp;but with a restricted magnitude.
What are non-saturating activation functions?	Activation functions that do not converge on a constant value for extremely negative or positive input values.&nbsp;Standard sigmoid functions saturate at large inputs, causing their gradients to become zero, which contributes to the vanishing gradient problem. Choosing non-saturating functions, such as ReLU variants, addresses this issue.
What is a residual network?	A residual network is composed of residual layers. Each layer is defined by the function&nbsp;\(F'_l(x) = F_l(x) + x\), where&nbsp;\(F_l(x)\)&nbsp;represents the standard linear-activation-linear mapping. The primary benefit of this design is that it offers a 'short cut' which allows gradients to flow directly from the output layer to any previous layer, aiding in the training of very deep networks.
Why is parameter initialisation important?	The optimisation landscape for neural network training is non-convex (possessing many local minima/'valleys'), the starting position (the choice of initial weights) is important as standard gradient descent will converge to the local optimum corresponding to that starting point.
What is early stopping?	A method used to prevent overfitting in neural networks (and other models). A validation dataset is created, and training is stopped when the error on this validation set begins to increase, indicating that the model is starting to overfit the training data.
What is weight decay?	Also known as&nbsp;\(\ell_2\)&nbsp;regularisation, this method reduces overfitting by modifying the loss function. A penalty term,&nbsp;\(\lambda w^\top w\)&nbsp;(where&nbsp;\(w\)&nbsp;is the weight vector and&nbsp;\(\lambda &gt; 0\)&nbsp;is a user-chosen parameter), is added to the cost function to penalize large weights. This penalty term is the square of the 2-norm, or Euclidean norm, of the weight vector, \(||w||_2^2\).
What is dropout?	"A regularisation method for preventing overfitting in neural networks. During training, a unit's outgoing connections are randomly deactivated (removed) with a specified probability. This is done on a per-example basis—a new ""thinned network"" is sampled and trained for each presentation of a training case. This process forces units to become robust and prevents them from learning complex, fragile dependencies on specific other units."
How does an individual unit compute its output value?	A unit&nbsp;\(j\)&nbsp;first computes&nbsp;\(a_j\), a weighted sum of its inputs (\(z_i\)) from the previous layer, and then passes&nbsp;\(a_j\)&nbsp;to a nonlinear activation function&nbsp;\(h\)&nbsp;to determine its output&nbsp;\(z_j\):&nbsp;\(a_j = \sum_i w_{ji}z_i\), \(z_j = h(a_j)\).
What is the back propagation formula?	"\[\delta_j = h'(a_j) \sum_k w_{kj}\delta_k\]\(\mathbf{\delta_j}\): The error signal for unit&nbsp;\(j\).<br>\(a_j\)<span style=""white-space: pre;"">:</span>&nbsp;The total weighted sum of inputs received by unit&nbsp;\(j\)&nbsp;before the activation function is applied.<br>\(h'(a_j)\): Represents the derivative of the activation function,&nbsp;\(h\).<br>\(\sum_k\): Indicates the summation over all units&nbsp;\(k\)&nbsp;in the subsequent layer to which unit&nbsp;\(j\)&nbsp;sends connections.<br>\(w_{kj}\): The weight parameter connecting unit&nbsp;\(j\)&nbsp;to unit&nbsp;\(k\)&nbsp;in the next layer.<br>\(\delta_k\): The previously calculated error signal (\(\equiv \frac{\partial E_n}{\partial a_k}\)) for unit&nbsp;\(k\)&nbsp;in the layer subsequent to&nbsp;\(j\)."
